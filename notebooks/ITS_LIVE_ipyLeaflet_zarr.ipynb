{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f51eb21",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <h1><center>\n",
    "        <img src=\"https://its-live-data.s3.amazonaws.com/documentation/ITS_LIVE_logo.png\" width=\"500\"/>\n",
    "        </center></h1>\n",
    "    <h1><center>\n",
    "        Global glacier velocity point data access<br>\n",
    "        using an ipyLeaflet basemap<br>\n",
    "        </center></h1>\n",
    "</div>\n",
    "\n",
    "***\n",
    "\n",
    "Author: Mark Fahnestock, Geophysical Institute, University of Alaska Fairbanks\n",
    "Date: November 8, 2021\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9dd6b76",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "This notebook allows you to select a set of point locations on a Leaflet-based global map, fetch all available ITS_LIVE glacier velocities for the locations, and plot the results.\n",
    "\n",
    "Select the points by double-clicking on the map - click and drag on the map to pan the field of view.\n",
    "\n",
    "Once points are chosen, hit \"Make Plot\" (bottom right corner) to produce a plot.\n",
    "\n",
    "You can drag individual points after they are placed to relocate them, and then \"Make Plot\" again\n",
    "\n",
    "Click \"Clear Points\" to start over.\n",
    "\n",
    "The notebook is set up to show data coverage for a small set of \"All Satellite\" datacubes by default (parts of Greenland/Svalbard/Alaska only for now), but if you select Landsat 8 it will instead use a global collection of Landsat 8 datacubes.\n",
    "\n",
    "Underling data is stored on AWS S3 as Zarr datacubes and is accessed without an intermediate server. Glacier velocities in the \"All Satellite\" datacube collection are derived from all available Landsat 8, Sentinel-1A/B, Sentinel-2A/B imagery, while they are limited to Landsat 8 for now in the global dataset.\n",
    "\n",
    "\n",
    "Please refer to the <a href=\"https://its-live.jpl.nasa.gov/\">project website</a> for further product infomation and for appraopriate data citation.\n",
    "\n",
    "### Setting up a local environment\n",
    "\n",
    "From the repository root, run in a terminal:\n",
    "```shell\n",
    "conda env create -f binder/environment.yml\n",
    "```\n",
    "activate newly created environment:\n",
    "```shell\n",
    "conda activate itslive-notebooks\n",
    "```\n",
    "\n",
    "then start jupyter in browser\n",
    "```shell\n",
    "cd notebooks\n",
    "jupyter notebook\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330a2f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "# import the library\n",
    "from velocity_widget import ITSLIVE\n",
    "\n",
    "velocity_widget = ITSLIVE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc8e3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If this congiguration changes we need to rerun the cell.\n",
    "config = { \n",
    "    \"plot\": \"v\", # or other ITS_LIVE variables: vx, vy ...\n",
    "    \"min_separation_days\": 1,\n",
    "    \"max_separation_days\": 90,\n",
    "    \"color_by\": \"points\" # valid values: satellite, points\n",
    "}\n",
    "\n",
    "velocity_widget.set_config(config)\n",
    "velocity_widget.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2944e7a1",
   "metadata": {},
   "source": [
    "## Gathering and processing the data\n",
    "\n",
    "## Zarr and S3 cloud storage\n",
    "\n",
    "* Why Zarr? \n",
    "* Chunking of ITS_LIVE cubes\n",
    "\n",
    "### Working with ITS_LIVE zarr cubes in **xarray**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c65bffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can work directly with the xarray instances for the cubes that match our points in the map.\n",
    "# we can directly access a dictionary of currently open ITL_LIVE datacubes containing the points picked above\n",
    "# the keys for this dictionary are the s3 URI's for the xarray stores in zarr format\n",
    "zarr_cubes_dict = velocity_widget.dct.open_cubes\n",
    "print(f\"open datacubes (xarray datasets in zarr format): {zarr_cubes_dict.keys()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26f5573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The actual xarray is returned when the dictionary is indexed by the URI key \n",
    "#  - when opened on S3 it will take ~5-10 seconds to load the first time \n",
    "# Chunking was optimized for time series extraction at any given x and y.\n",
    "\n",
    "# NOTE that these cubes are open, but only the metadata and coordinates have been downloaded, not the data itself\n",
    "# THE DATA VOLUME IN THESE CUBES IS QUITE LARGE, fully loading variables for a whole cube could extend to multiple GB\n",
    "\n",
    "# here jupyter/ipython will pretty-print a table of metadata and variables for a cube if we reference one that is open:\n",
    "first_key = list(zarr_cubes_dict.keys())[0]\n",
    "print(f'First S3 URI for open cube: {first_key}')\n",
    "cube = zarr_cubes_dict[first_key]\n",
    "cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c722b16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
